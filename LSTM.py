import os
import numpy as np
import joblib
import csv
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# ===============================
# ë°ì´í„° ë¡œë”©
# ===============================
def load_data_flat(data_path):
    sequences = []
    labels = []

    for label in os.listdir(data_path):
        label_path = os.path.join(data_path, label)
        if not os.path.isdir(label_path):
            continue

        for file in os.listdir(label_path):
            if file.endswith('.npy'):
                sequence = np.load(os.path.join(label_path, file))
                if sequence.shape == (30, 144):
                    sequences.append(sequence)
                    labels.append(label)

    return np.array(sequences), labels

# ===============================
# ëª¨ë¸ êµ¬ì„±
# ===============================
def build_model(input_shape, num_classes, num_units, num_layers, dropout_rate):
    model = Sequential()
    model.add(LSTM(num_units, return_sequences=(num_layers > 1), input_shape=input_shape))
    for i in range(1, num_layers):
        model.add(LSTM(num_units, return_sequences=(i < num_layers - 1)))
        model.add(Dropout(dropout_rate))
    model.add(Dense(num_units // 2, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# ===============================
# í•™ìŠµ ë° í‰ê°€
# ===============================
def train_and_evaluate(X_train, y_train, X_test, y_test, model):
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])

    y_pred = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)

    acc = accuracy_score(y_true_classes, y_pred_classes)
    prec = precision_score(y_true_classes, y_pred_classes, average='macro')
    rec = recall_score(y_true_classes, y_pred_classes, average='macro')
    f1 = f1_score(y_true_classes, y_pred_classes, average='macro')

    return acc, prec, rec, f1

# ===============================
# ë©”ì¸ í•¨ìˆ˜
# ===============================
def main():
    DATA_PATH = '4-1/ì¢…í•©ì„¤ê³„/translation/sign_data'
    MODEL_SAVE_DIR = '4-1/ì¢…í•©ì„¤ê³„/translation/models'
    CSV_LOG_PATH = os.path.join(MODEL_SAVE_DIR, 'model_results.csv')
    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

    # CSV ì´ˆê¸°í™”
    with open(CSV_LOG_PATH, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['Model Name', 'Units', 'Layers', 'Dropout', 'Accuracy', 'Precision', 'Recall', 'F1'])

    # ë°ì´í„° ë¡œë”©
    X, y_labels = load_data_flat(DATA_PATH)
    le = LabelEncoder()
    y = le.fit_transform(y_labels)
    y_cat = to_categorical(y)

    joblib.dump(le, '4-1/ì¢…í•©ì„¤ê³„/translation/label_encoder.pkl')
    print("âœ… ë¼ë²¨ ì¸ì½”ë” ì €ì¥ ì™„ë£Œ")

    X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42, stratify=y)

    num_classes = len(np.unique(y))
    input_shape = (30, 144)

    # âœ… ì‹¤í—˜ ì¡°í•©
    unit_options = [128, 256]
    layer_options = [2, 3]
    dropout_options = [0.25, 0.5]

    best_f1 = 0
    best_model = None
    best_name = ""
    best_acc = best_prec = best_rec = 0  # âœ… ì„±ëŠ¥ ì €ì¥ìš© ë³€ìˆ˜

    for units in unit_options:
        for layers in layer_options:
            for dropout in dropout_options:
                print(f"\nğŸš€ Training: units={units}, layers={layers}, dropout={dropout}")
                model = build_model(input_shape, num_classes, units, layers, dropout)
                acc, prec, rec, f1 = train_and_evaluate(X_train, y_train, X_test, y_test, model)

                print(f"ğŸ“Š Accuracy: {acc:.2f}, Precision: {prec:.2f}, Recall: {rec:.2f}, F1: {f1:.2f}")

                model_name = f"sign_model_u{units}_l{layers}_d{int(dropout*100)}.h5"
                model_path = os.path.join(MODEL_SAVE_DIR, model_name)
                model.save(model_path)
                print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

                # ê²°ê³¼ CSV ì €ì¥
                with open(CSV_LOG_PATH, 'a', newline='') as f:
                    writer = csv.writer(f)
                    writer.writerow([model_name, units, layers, dropout, acc, prec, rec, f1])

                # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥
                if f1 > best_f1:
                    best_f1 = f1
                    best_acc = acc
                    best_prec = prec
                    best_rec = rec
                    best_model = model
                    best_name = model_name

    if best_model:
        best_model.save(os.path.join(MODEL_SAVE_DIR, 'sign_model_best_f1.h5'))

        # âœ… ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„±ëŠ¥ ì¶œë ¥
        print("\nğŸ† [ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½]")
        print(f"ğŸ“Œ ëª¨ë¸ ì´ë¦„     : {best_name}")
        print(f"ğŸ“Š Accuracy      : {best_acc:.2f}")
        print(f"ğŸ¯ Precision     : {best_prec:.2f}")
        print(f"ğŸ“ˆ Recall        : {best_rec:.2f}")
        print(f"â­ F1 Score       : {best_f1:.2f}")
        print(f"\nğŸ’¾ ì €ì¥ ê²½ë¡œ     : sign_model_best_f1.h5")
        print(f"ğŸ“„ ì „ì²´ ê²°ê³¼ CSV : {CSV_LOG_PATH}")

if __name__ == '__main__':
    main()
