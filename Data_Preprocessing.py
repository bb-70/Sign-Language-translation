import os
import cv2
import numpy as np
import mediapipe as mp

# ==============================
# ê²½ë¡œ ì„¤ì •
# ==============================
VIDEO_ROOT = '/Users/soyeon/4-1/ì¢…í•©ì„¤ê³„/translation/SLV'
SAVE_ROOT = '/Users/soyeon/4-1/ì¢…í•©ì„¤ê³„/translation/sign_data'

# ==============================
# MediaPipe ì´ˆê¸°í™”
# ==============================
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands
pose = mp_pose.Pose()
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2)

# ==============================
# ë¼ë²¨ í´ë” ìˆœíšŒ
# ==============================
for label in os.listdir(VIDEO_ROOT):
    label_path = os.path.join(VIDEO_ROOT, label)
    if not os.path.isdir(label_path):
        continue

    print(f"\n[âš™ï¸ ì²˜ë¦¬ ì‹œì‘] ë¼ë²¨: {label}")
    save_dir = os.path.join(SAVE_ROOT, label)
    os.makedirs(save_dir, exist_ok=True)

    existing = os.listdir(save_dir)
    saved_count = len([f for f in existing if f.endswith('.npy')])

    # ëª¨ë“  ì˜ìƒ íŒŒì¼ íƒìƒ‰
    video_files = [f for f in os.listdir(label_path) if f.endswith('.mp4')]

    for video_file in video_files:
        video_path = os.path.join(label_path, video_file)
        cap = cv2.VideoCapture(video_path)
        sequence = []

        print(f"ğŸ¥ ì˜ìƒ ì²˜ë¦¬ ì¤‘: {video_file}")

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret or frame is None:
                break

            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            if image is None or image.shape[0] == 0 or image.shape[1] == 0:
                print("âš ï¸ ì´ë¯¸ì§€ shape ì˜¤ë¥˜ â†’ ê±´ë„ˆëœ€")
                continue

            image.flags.writeable = False
            pose_result = pose.process(image)
            hands_result = hands.process(image)

            keypoints = []

            # í¬ì¦ˆ: ì–´ê¹¨~ì†ëª© (6ê°œ x 3)
            if pose_result.pose_landmarks:
                for idx in [11, 13, 15, 12, 14, 16]:
                    lm = pose_result.pose_landmarks.landmark[idx]
                    keypoints.extend([lm.x, lm.y, lm.z])
            else:
                keypoints.extend([0] * 18)

            # ì†: ìµœëŒ€ ì–‘ì†
            if hands_result.multi_hand_landmarks:
                detected_hands = hands_result.multi_hand_landmarks[:2]
                for hand in detected_hands:
                    for lm in hand.landmark:
                        keypoints.extend([lm.x, lm.y, lm.z])
                if len(detected_hands) == 1:
                    keypoints.extend([0]*63)
            else:
                keypoints.extend([0]*126)

            if len(keypoints) != 144:
                print(f"â— í‚¤í¬ì¸íŠ¸ ê¸¸ì´ ì˜¤ë¥˜: {len(keypoints)}, ê±´ë„ˆëœ€")
                continue

            sequence.append(keypoints)

            if len(sequence) == 30:
                npy_path = os.path.join(save_dir, f'{saved_count}.npy')
                np.save(npy_path, np.array(sequence))
                print(f"âœ… {saved_count}.npy ì €ì¥ ì™„ë£Œ")
                sequence = []
                saved_count += 1

        cap.release()

print("\nğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")
cv2.destroyAllWindows()

sample = np.load('/Users/soyeon/4-1/ì¢…í•©ì„¤ê³„/translation/sign_data/ëª»ìƒê¸°ë‹¤/0.npy')
print("Shape:", sample.shape)
print("Sample data (ì²« í”„ë ˆì„):", sample[0][:10])  # ì• 10ê°œë§Œ

